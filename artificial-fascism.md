# Artificial Fascism
`2021-08-15`

The power of automated judgement. What could possibly go wrong?

## Face detection

### The Best Algorithms Struggle to Recognize Black Faces Equally
> US government tests find even top-performing facial recognition systems misidentify blacks at rates five to 10 times higher than they do whites.
>
> &mdash; [Wired, 2019-07-22](https://www.wired.com/story/best-algorithms-struggle-recognize-black-faces-equally/)

### Twitter
> Trying a horrible experiment...
>
> Which will the Twitter algorithm pick: Mitch McConnell or Barack Obama?
>
> &mdash; [Tony Arcieri (@bascule), 2020-09-19](https://twitter.com/bascule/status/1307440596668182528)"

### Zoom
> Turns out [@zoom_us](https://twitter.com/zoom_us) has a crappy face-detection algorithm that erases black faces...and determines that a nice pale globe in the background must be a better face than what should be obvious.
>
> &mdash; [Colin Madland (@colinmadland), 2020-09-19](https://twitter.com/colinmadland/status/1307111825851416577)

## Credit score

## Fraud detection

### Machine Learning for Credit Card Fraud detection
> ML for credit card fraud detection is one of those fields where most of the published research is unfortunately not reproducible. Real-world transaction data cannot be shared for confidentiality reasons, but we also believe authors do not make enough efforts to provide their code and make their results reproducible.
>
> &mdash; [Towards Data Science, 2021-05-26](https://towardsdatascience.com/machine-learning-for-credit-card-fraud-detection-a-jupyter-book-for-reproducible-research-8ca5edad7b5d)

## Performance assessment

### Xsolla lays off 150 after an algorithm ruled staff 'unengaged and unproductive'
> Xsolla, a company that provides payment processing options for the game industry, has laid off roughly one-third of its workforce after an algorithm employed by the company decided those 150 individuals were "unengaged and unproductive employees".
>
> &mdash; [Gamasutra, 2021-08-10](https://www.gamasutra.com/view/news/386534/Xsolla_lays_off_150_after_an_algorithm_ruled_staff_unengaged_and_unproductive.php)

## Sentiment analysis

### Indigo Airline’s Twitter fiasco — Sentiment classification gone wrong
> Indigo airline’s (leading private airline in India) Twitter reply to a customer’s tweet last year gained lot of bad publicity for the airline. A disgruntled customer had tweeted about misplaced baggage, but it was a sarcastic tweet thanking them. Indigo’s reply was to thank the customer.
>
> &mdash; [Practical Data Science And Engineering, 2018-02-20](https://medium.com/practical-data-science-and-engineering/indigo-airlines-twitter-fiasco-sentiment-classification-gone-wrong-5802321468e2)

## Healthcare

### Millions of black people affected by racial bias in health-care algorithms
> An algorithm widely used in US hospitals to allocate health care to patients has been systematically discriminating against black people, a sweeping analysis has found.
>
> &mdash; [Nature, 2019-10-24](https://www.nature.com/articles/d41586-019-03228-6)

### How Algorithms Can Punish the Poor
> As Americans look for greater government efficiencies, we increasingly turn to automated systems that use algorithms to determine who is eligible for access to housing, welfare benefits, intervention from child protective services, and more.
>
> &mdash; [Slate, 2018-03-29](https://slate.com/human-interest/2018/03/automating-inequality-author-virginia-eubanks-on-how-algorithms-can-punish-the-poor.html)

## Law enforcement

### Wrongfully Accused by an Algorithm
> In what may be the first known case of its kind, a faulty facial recognition match led to a Michigan man's arrest for a crime he did not commit.
>
> &mdash; [New York Times, 2020-08-03](https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html)
